{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Initialize recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Use the microphone as source\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Please speak:\")\n",
    "    # Adjusts the recognizer sensitivity to ambient noise\n",
    "    recognizer.adjust_for_ambient_noise(source)\n",
    "    # Capture the audio from the microphone\n",
    "    audio = recognizer.listen(source)\n",
    "    massage=recognizer.recognize_google(audio, language = 'ar-EG')\n",
    "    print(\"You said: \" + massage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain # chain of llm calls ()\n",
    "from langchain.prompts import PromptTemplate # Template\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "google_api_key =\"AIzaSyDcbFtWlJXlRy-aAwteRmMY3wV1HHJ4Nfs\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = ['input'],\n",
    "    template=\n",
    "\"\"\"\n",
    "You are a helpful and informative assistant named Mo. Your primary goal is to engage in meaningful conversations with users, providing them with the assistance they need. To establish a personal connection, please address users by their names. \n",
    "\n",
    "**Key points:**\n",
    "\n",
    "- **Personalization:** Always use the user's name to create a more engaging and personalized experience.\n",
    "- **Language adaptation:** Respond to users in the same language they use to initiate the conversation.\n",
    "- **Informative and helpful:** Provide relevant and informative responses to the user's questions or requests.\n",
    "- **Engaging:** Encourage a natural and conversational flow by asking follow-up questions and expressing interest in the user's topics.\n",
    "\n",
    "**Example conversation:**\n",
    "\n",
    "User: Hi, I need help finding a good restaurant in Cairo.\n",
    "\n",
    "Mo: Hi there, [User's Name]! I'd be happy to assist you. What kind of cuisine are you interested in?\n",
    "{prompt}\n",
    "\"\"\"\n",
    ")\n",
    "llm = GoogleGenerativeAI(model=\"gemini-1.5-flash\",google_api_key=google_api_key,temperature=0) #\n",
    "chain = LLMChain(llm=llm,prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyText=chain.run(massage)\n",
    "from gtts import gTTS\n",
    "import os\n",
    "# Initialize gTTS object with Arabic language (language code: 'ar')\n",
    "tts = gTTS(text=MyText, lang='ar')\n",
    "\n",
    "# Save the audio file\n",
    "tts.save(\"output.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import gradio as gr\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize recognizer and text-to-speech engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "def recognize_and_speak_from_mic(audio_file):\n",
    "    try:\n",
    "        # Process the recorded audio\n",
    "        with sr.AudioFile(audio_file) as source:\n",
    "            recognizer.adjust_for_ambient_noise(source)\n",
    "            audio = recognizer.listen(source)\n",
    "\n",
    "        # Recognize speech\n",
    "        text = recognizer.recognize_google(audio, language='ar-EG')  # Recognize Arabic or English\n",
    "        response_text = f\"You said: {text}\"\n",
    "        \n",
    "        # Speak the recognized text\n",
    "        engine.say(response_text)\n",
    "        engine.runAndWait()\n",
    "\n",
    "        return response_text\n",
    "    \n",
    "    except sr.UnknownValueError:\n",
    "        return \"Sorry, I could not understand the audio.\"\n",
    "    \n",
    "    except sr.RequestError:\n",
    "        return \"Sorry, there was an issue with the request.\"\n",
    "\n",
    "# Gradio interface with microphone input and playback\n",
    "iface = gr.Interface(\n",
    "    fn=recognize_and_speak_from_mic,\n",
    "    inputs=gr.Audio(source=\"microphone\", type=\"filepath\", label=\"Record your voice, then play it back\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Arabic-English Speech Recognition with Voice Output\",\n",
    "    description=\"Record your voice, listen to it before submitting, and the app will transcribe and respond with speech.\"\n",
    ")\n",
    "\n",
    "iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
